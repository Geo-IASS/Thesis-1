% TODO: Find citations
The amount of data being collected and stored is continually increasing
\cite{Vries:2010}. Anomaly detection is an important technique which can be
applied to a wide range of applications. There are many techniques to detect and
measure anomalies, each usually most applicable to some specific problem domain
\citeNeeded{}.

A general algorithm for anomaly detection has proved difficult to design
\citeNeeded{}, due to various challenges associated with defining and measuring
anomalies. Most existing approaches are based on statistical or geometrical
measures involving distance. Whilst many algorithms work well for some subset of
input data sets, it has been difficult to discover an algorithm which performs
both correctly and efficiently on all possible data sets.

Previous research has found merit in applying randomization techniques to highly
multivariate data sets in order to reduce the dimensionality of these data sets
whilst maintaining their fundamental and statistical properties. Such reduction
of the dimensionality of data, assuming it can be performed efficiently, allows
previously-unscalable anomaly detection algorithms to be practically applied to
a wider range of data and applications.

Anomaly detection is an important and contemporary problem in the field of
computer science, and is of particular interesting to stock market analysis,
network intrusion detection and image comparison.

Detecting outliers, examples in a database with unusual properties, is an important data mining task. Recently researchers have begun focusing on this problem and have attempted to apply algorithms for finding outliers to tasks such as fraud detection, identifying computer network intrusions, data cleaning, and detecting employers with poor injury histories \cite{Bay:2003}.