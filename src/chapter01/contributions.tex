A key difficulty in anomaly detection is the efficient scaling of a general
algorithm to apply to highly multivariate data \citeNeeded{}. In particular,
time, cost and energy efficiency are critical factors for many data analysis
techniques when the size and dimensionality of data is very large
\cite{Vries:2011}. In this \thesis{}, I explore the use of randomization
techniques (such as random projections and commute time) in anomaly detection
algorithms.

Furthermore, in this \thesis{} I attempt to make observations and an analysis of
the run-time performance of anomaly detection algorithms using randomization
techniques, so as to identify steps in the algorithms that bottleneck the
algorithm's performance. Through this identification it would be possible to
improve the \emph{actual} run-time performance of the algorithm by utilising the
advantages of reconfigurable computing.

These techniques provide encouraging results with regards to the run-time
complexity of an algorithm, and provide great opportunities for many modern
applications, including financial trading, security analysis and many real-time
data models.