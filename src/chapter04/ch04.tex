\chapter{Design}
\label{ch:design}

\section{Introduction}
\label{sec:designIntroduction}

% ALGORITHM PROFILING
\section{Algorithm Profiling}
\label{sec:algorithmProfiling}
In order to choose which step of the algorithm would be best suited for 
implementation on FPGA hardware, it was first necessary to first profile the 
execution of the algorithm using various test cases. This task was performed 
using MATLAB, using code supplied by \citeauthor{Khoa:2012} that was used to 
test and verify the conclusions of \citetitle{Khoa:2012}. Using \emph{MATLAB}'s 
\verb+profile+ command, I was able to analyse the algorithm and make an 
assessment of the running time of the algorithm. The results of the algorithm 
profiling can be found in 
\hyperref[apdx:algorithmProfiling]{Appendix~\ref{apdx:algorithmProfiling}}. 

% PERFORMANCE BOTTLENECK
\subsection{Performance Bottleneck}
\label{sec:algorithmPerformanceBottleneck}
From observations of the results of the algorithm profiling, it was observed 
that the performance of the `anomaly detection using commute-distance' 
algorithm is bottlenecked significantly by a function named 
\verb+TopN_Outlier_Pruning_Block+. The MATLAB code for this function can be 
found in \hyperref[apdx:matlabCode]{Appendix~\ref{apdx:matlabCode}}. Analysis of
this function, as well as discussions with \citeauthor{Khoa:2012} revealed that
the algorithm was originally devised by \citeauthor{Bay:2003} and published in
the paper \citetitle{Bay:2003}. The general steps of the algorithm are described
in \hyperref[algm:TopNOutlierPruningBlock]
{Algorithm~\ref{algm:TopNOutlierPruningBlock}}.

\begin{algorithm}
\caption{TopN\_Outlier\_Pruning\_Block}
\label{algm:TopNOutlierPruningBlock}

\LinesNumbered

\SetKwInput{InputK}{k}
\SetKwInput{InputN}{N}
\SetKwInput{InputD}{Data}
\SetKwInOut{OutputO}{outliers}

\InputK{the number of nearest neighbors}
\InputN{the number of outliers to return}
\InputD{a set of examples in random order}
\OutputO{a set of outliers}

\SetKwData{varB}{b}
\SetKwData{Block}{block}
\SetKwData{Cutoff}{cutoff}
\SetKwData{varD}{d}
\SetKwData{Data}{Data}
\SetKwData{varK}{k}
\SetKwData{varN}{N}
\SetKwData{Neighbours}{neighbours}
\SetKwData{varO}{o}
\SetKwData{Outliers}{outliers}
\SetKwData{Score}{score}

\SetKwFunction{Closest}{closest}
\SetKwFunction{Distance}{distance}
\SetKwFunction{GetNextBlock}{getNextBlock}
\SetKwFunction{MaxDist}{maxDist}
\SetKwFunction{Min}{min}
\SetKwFunction{Top}{top}

\Begin{
	$\Cutoff \longleftarrow 0$\tcp*[l]{set the cutoff for pruning to $0$}
	$\Outliers \longleftarrow \emptyset$\tcp*[l]{initialize to the empty set}
	\BlankLine
	\While(\tcp*[h]{load a block of examples from \varD}){$\Block \longleftarrow \GetNextBlock{\Data}$}{
		$\Neighbours(\varB) \longleftarrow \emptyset, \quad \forall \, \varB \in \Block$\;
		\BlankLine
		\ForEach{$\varD \in \Data$}{
			\ForEach{$\varB \in \Block \: : \: \varB \neq \varD$}{
				\If{$|\Neighbours(\varB)| < \varK \: \lor \: \Distance{\varB, \varD} < \MaxDist{\varB, \Neighbours(\varB)}$}{
					$\Neighbours(\varB) \longleftarrow \Closest{\varB, \Neighbours(\varB)} \cup \varD, \varK)$\;
					\If{$\Score(\Neighbours(\varB), \varB) < \Cutoff$}{
						$\Block \longleftarrow \Block \setminus \varB$\;
					}
				}
			}
		}
		\BlankLine
		$\Outliers \longleftarrow $\Top{$\Block \cup \Outliers$, $\varN$}\tcp*[l]{keep only the top n outliers}
		$\Cutoff \longleftarrow \Min_{\varO \in \Outliers}(\Score(\varO))$\tcp*[l]{the cutoff is the score of the weakest outlier}
	}
	\KwRet{\Outliers}\;
}
\end{algorithm}
